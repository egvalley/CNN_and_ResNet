{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd11d6f-1ee4-405c-a0c9-17b2d361cea7",
   "metadata": {},
   "source": [
    "# Establish CNNs from scratch\n",
    "The dense layer is also called the fully connected layer. The input is the flattened one-column vector from the last convolution-pooling layer by the reshaping process. The output would be a N-dimensional  vector, where N is the number of categories. For the dense layer, **Forward Propagation** and **Backward Propagation** are the same with those of a single-layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8731e7-1a9f-469f-a4b6-10465970f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from layer import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2980fd",
   "metadata": {},
   "source": [
    "The formula of **Forward Propagation** goes as follows:\n",
    "$$\n",
    "Y=W \\cdot X+B\n",
    "$$  \n",
    "$$\n",
    "Y=\n",
    "\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{j} \\\\\n",
    "\\end{bmatrix}  \n",
    "\\;\n",
    "W=\n",
    "\\begin{bmatrix}\n",
    "\\omega_{11} & \\omega_{21} & \\dots & \\omega_{i1}\\\\\n",
    "\\omega_{12} & \\omega_{22} & \\dots & \\omega_{i2}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\omega_{1j} & \\omega_{2j} & \\dots & \\omega_{ij}\\\\\n",
    "\\end{bmatrix}\n",
    "\\;\n",
    "X=\n",
    "\\begin{bmatrix}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{i} \\\\\n",
    "\\end{bmatrix}  \n",
    "\\;\n",
    "B=\n",
    "\\begin{bmatrix}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{j} \\\\\n",
    "\\end{bmatrix}  \n",
    "\\;\n",
    "$$\n",
    "The formula of **Backward Propagation** goes as follows:\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial X} = W^T \\cdot \\frac{\\partial E}{\\partial Y}\n",
    "$$  \n",
    "The formulas of **Gredient Descent** go as follows:\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial W} = \\frac{\\partial E}{\\partial Y} \\cdot X^T\n",
    "$$  \n",
    "$$\n",
    "\\frac{\\partial E}{\\partial B} = \\frac{\\partial E}{\\partial Y}\n",
    "$$  \n",
    "Hence\n",
    "$$\n",
    "W \\leftarrow W-\\alpha \\frac{\\partial E}{\\partial W}\n",
    "$$  \n",
    "$$\n",
    "B \\leftarrow B-\\alpha \\frac{\\partial E}{\\partial B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46718d60-35bd-41cf-98ba-17abaee892d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
