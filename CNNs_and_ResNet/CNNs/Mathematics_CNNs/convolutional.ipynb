{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9dd31b2-358c-4490-8627-1e56bbddede0",
   "metadata": {},
   "source": [
    "# Establish CNNs from scratch\n",
    "This file fouces on **Forward Propogation** and **Backward Propogation** in convolutional layers of CNNs. In this file, the convolutional layer is separated from the convolution-pooling layer, which is composed by three layers, namely \"convolutional layer\",\"activation layer\",and\"pooling layer\".\\\\\n",
    "\n",
    "\n",
    "A convolutional layer is a core building block of CNNs, where the input image is processed using a set of learnable filters, also known as kernels. This operation allows the network to be sensitive to spatial hierarchies of features in the input data, making it well-suited for processing data with a grid-like topology, such as images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc1bb7c-9097-45a1-8254-395d94727368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from layer import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307328d-b9af-404c-b299-7d8303372885",
   "metadata": {},
   "source": [
    "### 1.Some definitions\n",
    "Define the operator of \"Cross-Correlation\" as \"$\\star$\", which has two different types denoted by \"$\\underset{\\scriptstyle full}{\\star}$\" and \"$\\underset{\\scriptstyle valid}{\\star}$\".  \n",
    "\\\n",
    "Define the operator of \"Full Convolution\" as \"$\\underset{\\scriptstyle full}{\\ast}$\", which is defined by $ I \\; \\underset{\\scriptstyle full}{\\ast} \\; K = I \\; \\underset{\\scriptstyle full}{\\star} \\; rot180(K) $ .  \n",
    "\n",
    "### 2.Formulas in **Forward Propogation** and **Backward Propogation**\n",
    "The formula of **Forward Propagation** goes as follows:\n",
    "$$ \n",
    "Y_{i} = B_{i} +  \\sum_{j=1}^{n_{c}}X_{j} \\underset{\\scriptstyle valid}{\\star} K_{ij} \\qquad i = 1,\\ldots,d \\tag{1}\n",
    "$$  \n",
    "where $X_{j}$ stands for a single channel of the original input, which could also be inheritted from the previous layer with a certain depth; $K_{ij}$ stands for a corresponding kernel, which is implemented with the cross-correlation operation; $Y_{i}$ stands for the output; $d$ stands for the depth of the output.  \n",
    "\\\n",
    "The formulas of **Backward Propagation** go as follows:\n",
    "$$ \n",
    "\\frac{\\partial E}{ \\partial X_{j}}=\\sum_{i=1}^{d} \\frac{\\partial E}{\\partial Y_{i}}\\underset{\\scriptstyle full}{\\ast} \\partial K_{ij} \\tag{2}\n",
    "$$  \n",
    "### 3.**Gredient Descent** method\n",
    "Updating weights and biases follows the classic \"Gradient  Descent\" strategy:\n",
    "$$ \n",
    "\\frac{\\partial E}{ \\partial K_{ij}}=X_{j} \\underset{\\scriptstyle valid}{\\star} \\frac{\\partial E}{\\partial Y_{i}} \\tag{3}\n",
    "$$\n",
    "$$ \n",
    "\\frac{\\partial E}{ \\partial B_{i}}=\\frac{\\partial E}{\\partial Y_{i}} \\tag{4}\n",
    "$$  \n",
    "Hence\n",
    "$$\n",
    "K_{ij} \\leftarrow K_{ij} - \\alpha \\frac{\\partial E}{ \\partial K_{ij}} \\tag{5}\n",
    "$$\n",
    "$$\n",
    "B_{i} \\leftarrow B_{i} - \\alpha \\frac{\\partial E}{\\partial B_{i}} \\tag{6}\n",
    "$$  \n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e248b1-2d44-40d8-8b06-ae53b9e54b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "    def __init__(self, input_shape:tuple, kernel_size:int, depth:int):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, input:np.ndarray):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases)\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        kernels_gradient = np.zeros(self.kernels_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                kernels_gradient[i, j] = signal.correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
    "                input_gradient[j] += signal.convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
